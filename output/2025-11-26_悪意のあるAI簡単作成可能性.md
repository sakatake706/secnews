- **収集元サイト**
Knowbe4 JP

- **掲載日**
2025-11-26

- **タイトル**
悪意のあるAI簡単作成可能性

- **概要**
Anthropicの研究により攻撃者は想定より容易にAIモデルの学習データを汚染可能であることが判明した。学習データ汚染によりモデルは悪意ある出力を生成し後続攻撃を誘発する。攻撃者はAIにフィッシングサイトリンク生成やコードへのバックドア埋め込みを促せる。研究は大規模データポイズニング調査でありモデル規模に関係なく250件の悪意ドキュメントでバックドア埋め込み可能と示した。これによりAIポイズニングの実現性が高いことが示唆される。

- **URL**
https://www.knowbe4.jp/blog/report-ai-poisoning-attacks-are-easier-than-previously-thought

- **備考**
攻撃者は学習データを汚染しAIモデルに悪意ある挙動を埋め込むことを狙う。攻撃目的はフィッシングやバックドア設置でありTTPは少数の悪意ドキュメント注入である。推奨対策は学習データの厳格管理と異常検知強化である。類似事例として他のAIモデル汚染攻撃が報告されている。将来は攻撃高度化と被害拡大が懸念される。専門家は継続的監視と対策強化を推奨する。

- **分類**
[[脅威トレンド]]

- **組織名**
N/A

- **業種**
N/A

- **攻撃手口**
[[マルウェア]]

- **攻撃影響**
N/A

- **脅威アクター**
N/A

- **原因**
学習データ管理強化、異常検知強化、従業員教育強化

- **対処方法**
#AIセキュリティ #データポイズニング #KnowBe4
